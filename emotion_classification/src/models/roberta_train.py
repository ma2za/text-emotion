# -*- coding: utf-8 -*-
"""roberta_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11EZJHL5SeCZWOzV6J6t3yW_vSsa9W-7u
"""

!git clone https://github.com/ma2za/emotion-classification.git

!mv emotion-classification/emotion_classification/src/roberta_emotion roberta_emotion

!pip install -q transformers datasets evaluate wandb "ray[tune]"

import itertools
import os
import random
from functools import partial
from typing import Dict

import numpy as np
import pandas as pd
import torch
import wandb
from datasets import ClassLabel, Features, Value
from datasets import Dataset
from datasets import concatenate_datasets
from datasets import load_dataset
from evaluate import evaluator
from huggingface_hub import notebook_login
from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler
from sklearn.metrics import accuracy_score, f1_score
from torch.optim import AdamW
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm
from transformers import RobertaTokenizer
from transformers.data.data_collator import default_data_collator

from roberta_emotion.modeling_roberta_emotion import RobertaEmotion
from roberta_emotion.configuration_roberta_emotion import RobertaEmotionConfig

torch.manual_seed(0)
random.seed(0)
np.random.seed(0)

# Commented out IPython magic to ensure Python compatibility.
# %env RAY_PICKLE_VERBOSE_DEBUG=1

# Commented out IPython magic to ensure Python compatibility.
# %env WANDB_PROJECT=emotion_classifier

wandb.login()

notebook_login()

device = "cuda" if torch.cuda.is_available() else "cpu"

"""## Tokenizer"""

tokenizer = RobertaTokenizer.from_pretrained("roberta-base")

def tokenization(sample):
    return tokenizer(sample["text"], padding=True, truncation=True)

"""## Dataset"""

dataset = load_dataset("emotion")

daily_dialog = load_dataset("daily_dialog")

daily_dialog = concatenate_datasets([daily_dialog["train"], daily_dialog["validation"], daily_dialog["test"]])

def merge_daily_dialog(examples):
    dd2emo = {
        1: "anger",
        3: "fear",
        4: "joy",
        5: "sadness",
        6: "surprise"
    }

    return {"chunks": [ {"text": d, "label": dd2emo[e]} for d, e in zip(examples["dialog"], examples["emotion"]) if e in [1, 3, 4, 5, 6] and len(d) < 85]}

temp = daily_dialog.map(merge_daily_dialog, remove_columns=daily_dialog.column_names)

features = Features({'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None) ,
 'text': Value(dtype='string', id=None)})

daily_dialog = Dataset.from_pandas(pd.DataFrame(list(itertools.chain(*temp["chunks"]))),
                                   features=features)

DATASETS = ["emotion"]
#DATASETS = ["emotion", "daily_dialog"]

if len(DATASETS) != 1:
    dataset["train"]  = concatenate_datasets([dataset["train"], daily_dialog])

dataset = dataset.map(tokenization, batched=True, batch_size=None)

dataset.set_format("torch", columns=["input_ids", "label"])

id2label =  {
    0: "sadness",
    1: "joy",
    2: "love",
    3: "anger",
    4: "fear",
    5: "surprise"
  }

label2id = {
    "sadness": 0,
    "joy": 1,
    "love": 2,
    "anger": 3,
    "fear": 4,
    "surprise": 5
  }

train_dataset = dataset["train"]
train_dataset.remove_columns(["text"])

valid_dataset = dataset["validation"]
valid_dataset.remove_columns(["text"])

"""## Model"""

RobertaEmotionConfig.register_for_auto_class()

RobertaEmotion.register_for_auto_class("AutoModel")

model_config = {
    "id2label": id2label,
    "label2id": label2id,
    "hidden_size": 768,
    "num_labels": 6
}

emotion_config = RobertaEmotionConfig(**model_config)

"""## Training"""

def compute_metrics(preds, labels):
    f1 = f1_score(labels, preds, average="weighted")
    acc = accuracy_score(labels, preds)
    return acc, f1

def evaluation(model, dataloader):
    model.eval()
    total_samples = 0
    total_loss = 0
    total_acc = 0
    total_f1 = 0
    for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)):
        input_ids = batch["input_ids"].to(device)
        labels = batch["labels"].to(device)
        outputs = model(input_ids=input_ids, labels=labels)
        acc, f1 = compute_metrics(outputs.logits.argmax(-1).detach().cpu(), labels.detach().cpu())
        total_acc += acc*len(labels)
        total_f1 += f1*len(labels)
        total_samples += len(labels)
        total_loss += outputs.loss.detach().cpu()*len(labels)
    return total_acc/total_samples, total_f1/total_samples, total_loss/total_samples

def train(model, checkpoint_dir, optimizer, lr_scheduler, train_loader, 
          valid_loader, tune_flag=False, config={}):
    wandb.init(project="emotion_classifier", config=config)

    best_f1 = 0
    for epoch in range(config["epochs"]):
        model.train()
        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):
            model.zero_grad()
            input_ids = batch["input_ids"].to(device)
            labels = batch["labels"].to(device)
            outputs = model(input_ids=input_ids, labels=labels)
            outputs.loss.backward()

            optimizer.step()
            lr_scheduler.step()
        valid_acc, valid_f1, valid_loss = evaluation(model, valid_loader)
        wandb.log({"eval/loss": valid_loss, "eval/f1": valid_f1, 
                   "eval/accuracy": valid_acc, 
                   "train/loss": outputs.loss.detach().cpu()})

        if tune_flag:

            with tune.checkpoint_dir(epoch) as checkpoint_dir:
                path = os.path.join(checkpoint_dir, "checkpoint")
                torch.save((model.state_dict(), optimizer.state_dict()), path)

            tune.report(loss=valid_loss, accuracy=valid_acc)
        else:
            if best_f1 < valid_f1:
                best_f1 = valid_f1
                path = os.path.join(checkpoint_dir, "pytorch_model.bin")
                torch.save(model.state_dict(), path)

    wandb.finish()

def train_roberta(config: Dict, checkpoint_dir: str = None):
    train_loader = DataLoader(
        train_dataset,
        batch_size=int(config["batch_size"]),
        collate_fn=default_data_collator,
        drop_last=False,
        num_workers=0,
        pin_memory=True
    )

    valid_loader = DataLoader(
        valid_dataset,
        batch_size=int(config["batch_size"]),
        collate_fn=default_data_collator,
        drop_last=False,
        num_workers=0,
        pin_memory=True
    )

    num_warmup_steps = float(len(train_loader) * config["epochs"] * config["warmup_ratio"])

    model = RobertaEmotion(emotion_config).to(device)
    optimizer = AdamW(model.parameters(), lr=config["lr"], betas=(0.9, 0.999), eps=1e-08)

    def lr_lambda(x: float, warmup: float):
        return 1.0 if x >= warmup else x / warmup

    lr_scheduler = LambdaLR(optimizer, partial(lr_lambda, warmup=num_warmup_steps))
    train(model, checkpoint_dir, optimizer, lr_scheduler, train_loader, valid_loader, config=config)
    return model

def tuning():
    data_dir = os.path.abspath("./data")
    config = {
        "batch_size": tune.choice([32, 64, 128])
    }
    scheduler = ASHAScheduler(
        metric="loss",
        mode="min",
        max_t=10,
        grace_period=1,
        reduction_factor=2)
    reporter = CLIReporter(
        # ``parameter_columns=["l1", "l2", "lr", "batch_size"]``,
        metric_columns=["loss", "accuracy", "training_iteration"])
    result = tune.run(
        partial(train_roberta, data_dir=data_dir),
        resources_per_trial={"cpu": 1, "gpu": 1},
        config=config,
        num_samples=10,
        scheduler=scheduler,
        progress_reporter=reporter)

    best_trial = result.get_best_trial("loss", "min", "last")

    best_trained_model = RobertaEmotion(emotion_config).to(device)

    best_checkpoint_dir = best_trial.checkpoint.value
    model_state, optimizer_state = torch.load(os.path.join(
        best_checkpoint_dir, "checkpoint"))
    best_trained_model.load_state_dict(model_state)

train_config = {"batch_size": 64,
                "epochs": 25,
                "lr": 1e-05,
                "warmup_ratio": 0.2,
                "datasets": DATASETS}

model = train_roberta(train_config, checkpoint_dir=".")

model_state = torch.load(os.path.join(".", "pytorch_model.bin"))
model.load_state_dict(model_state)

model.push_to_hub("roberta-emotion")
tokenizer.push_to_hub("roberta-emotion")

"""## Evaluation"""

task_evaluator = evaluator("text-classification")

results = task_evaluator.compute(
    model_or_pipeline=model,
    tokenizer=tokenizer,
    data="emotion",
    subset="split",
    split="test",
    metric="accuracy",
    label_mapping=label2id,
    strategy="bootstrap",
    n_resamples=10,
    random_state=0
)

results

