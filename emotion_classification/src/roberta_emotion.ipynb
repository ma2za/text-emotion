{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ma2za/emotion-classification.git"
      ],
      "metadata": {
        "id": "59LLJSo6wHaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv emotion-classification/emotion_classification/src/roberta_emotion roberta_emotion"
      ],
      "metadata": {
        "id": "Q6g7WexjxIyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets evaluate wandb \"ray[tune]\""
      ],
      "metadata": {
        "id": "iTvyV2vhFjJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTZp94-9A8Mf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from evaluate import evaluator\n",
        "from huggingface_hub import notebook_login\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "from transformers.optimization import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from roberta_emotion.modeling_roberta_emotion import RobertaEmotion\n",
        "from roberta_emotion.configuration_roberta_emotion import RobertaEmotionConfig"
      ],
      "metadata": {
        "id": "DhInzzztxy9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "64i4NV5z7hsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env RAY_PICKLE_VERBOSE_DEBUG=1"
      ],
      "metadata": {
        "id": "egzJy5JvESV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT=emotion_classifier"
      ],
      "metadata": {
        "id": "FvvXTHMPrGjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "KnIPHQ7-qsnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "nUeYzOHrq26P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "wq8FexcaGMGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "dIHT0h-uvy_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "hoUKEHGTajux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenization(sample):\n",
        "    return tokenizer(sample[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "WtFKa4SVageE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "tZaZE0YPvw0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"emotion\")"
      ],
      "metadata": {
        "id": "XLOQE-yrGjhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(tokenization, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "N1Y-r15obTPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.set_format(\"torch\", columns=[\"input_ids\", \"label\"])"
      ],
      "metadata": {
        "id": "YGsjKIq_wNWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label =  {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "  }\n",
        "\n",
        "label2id = {\n",
        "    \"sadness\": 0,\n",
        "    \"joy\": 1,\n",
        "    \"love\": 2,\n",
        "    \"anger\": 3,\n",
        "    \"fear\": 4,\n",
        "    \"surprise\": 5\n",
        "  }"
      ],
      "metadata": {
        "id": "wrpWsH2-rFk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "train_dataset.remove_columns([\"text\"])\n",
        "\n",
        "valid_dataset = dataset[\"validation\"]\n",
        "valid_dataset.remove_columns([\"text\"])"
      ],
      "metadata": {
        "id": "IDqhkAzgPDIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "vbw8tpwfwDyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RobertaEmotionConfig.register_for_auto_class()"
      ],
      "metadata": {
        "id": "_v-Yu1fXZ2kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RobertaEmotion.register_for_auto_class(\"AutoModel\")"
      ],
      "metadata": {
        "id": "ETurkMwqZ8Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_config = RobertaEmotionConfig(id2label = id2label, \n",
        "                              label2id = label2id, \n",
        "                              hidden_size = 768,\n",
        "                              num_labels = 6)"
      ],
      "metadata": {
        "id": "DY2KC7O3j938"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "qGXulHvDwQq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(preds, labels):\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return acc, f1"
      ],
      "metadata": {
        "id": "-Y8b4S-enJ3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, dataloader):\n",
        "    model.eval()\n",
        "    total_samples = 0\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_f1 = 0\n",
        "    for step, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        outputs = model(input_ids=input_ids, labels=labels)\n",
        "        acc, f1 = compute_metrics(outputs.logits.argmax(-1).detach().cpu(), labels.detach().cpu())\n",
        "        total_acc += acc*len(labels)\n",
        "        total_f1 += f1*len(labels)\n",
        "        total_samples += len(labels)\n",
        "        total_loss += outputs.loss.detach().cpu()*len(labels)\n",
        "    return total_acc/total_samples, total_f1/total_samples, total_loss/total_samples"
      ],
      "metadata": {
        "id": "wHEM40l95uqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, checkpoint_dir, optimizer, lr_scheduler, train_loader, valid_loader, tune_flag=False, config={}):\n",
        "    wandb.init(project=\"emotion_classifier\")\n",
        "\n",
        "    wandb.config = config\n",
        "\n",
        "    best_f1 = 0\n",
        "    model.backbone.requires_grad = False\n",
        "    for epoch in range(8):\n",
        "        model.train()\n",
        "        if epoch > 2:\n",
        "            model.backbone.requires_grad = True\n",
        "        for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "            model.zero_grad()\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, labels=labels)\n",
        "            outputs.loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "        valid_acc, valid_f1, valid_loss = evaluation(model, valid_loader)\n",
        "        wandb.log({\"eval/loss\": valid_loss, \"eval/f1\": valid_f1, \"eval/accuracy\": valid_acc})\n",
        "\n",
        "        if tune_flag:\n",
        "\n",
        "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "                path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "                torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "            tune.report(loss=valid_loss, accuracy=valid_acc)\n",
        "        else:\n",
        "            if best_f1 < valid_f1:\n",
        "                best_f1 = valid_f1\n",
        "                path = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "                torch.save(model.state_dict(), path)\n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "GUNPC0AJRMLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_roberta(config, checkpoint_dir=None):\n",
        "    train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=int(config[\"batch_size\"]),\n",
        "                collate_fn=default_data_collator,\n",
        "                drop_last=False,\n",
        "                num_workers=0,\n",
        "                pin_memory=True\n",
        "                )\n",
        "\n",
        "    valid_loader = DataLoader(\n",
        "                valid_dataset,\n",
        "                batch_size=int(config[\"batch_size\"]),\n",
        "                collate_fn=default_data_collator,\n",
        "                drop_last=False,\n",
        "                num_workers=0,\n",
        "                pin_memory=True\n",
        "            )\n",
        "    \n",
        "    num_training_steps=len(train_loader)*config[\"epochs\"]\n",
        "\n",
        "    model = RobertaEmotion(emotion_config).to(device)\n",
        "    optimizer = AdamW(model.parameters(),lr=config[\"lr\"], betas= (0.9, 0.999), eps= 1e-08)\n",
        "    lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(num_training_steps/3), \n",
        "                                                   num_training_steps=num_training_steps)\n",
        "\n",
        "\n",
        "    train(model, checkpoint_dir, optimizer, lr_scheduler, train_loader, valid_loader, config)\n",
        "    return model"
      ],
      "metadata": {
        "id": "pGuuTj5N-59u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tuning():\n",
        "    data_dir = os.path.abspath(\"./data\")\n",
        "    config = {\n",
        "        \"batch_size\": tune.choice([32, 64, 128])\n",
        "    }\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=10,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = CLIReporter(\n",
        "        # ``parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"]``,\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    result = tune.run(\n",
        "        partial(train_roberta, data_dir=data_dir),\n",
        "        resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
        "        config=config,\n",
        "        num_samples=10,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "\n",
        "    best_trained_model = RobertaEmotion(emotion_config).to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)"
      ],
      "metadata": {
        "id": "j-RZW8IRHJr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_roberta({\"batch_size\": 64, \n",
        "                       \"epochs\": 10,\n",
        "                       \"lr\": 5e-05}, checkpoint_dir=\".\")"
      ],
      "metadata": {
        "id": "ndJjf5uXHMdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state = torch.load(os.path.join(\".\", \"pytorch_model.bin\"))\n",
        "model.load_state_dict(model_state)"
      ],
      "metadata": {
        "id": "9NOMeUZSDPcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"roberta-emotion\")\n",
        "tokenizer.push_to_hub(\"roberta-emotion\")"
      ],
      "metadata": {
        "id": "fBZ9vsTzC51f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "gkzTXnTWwVbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_evaluator = evaluator(\"text-classification\")"
      ],
      "metadata": {
        "id": "nG4Csiq44C_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=\"emotion\",\n",
        "    subset=\"split\",\n",
        "    split=\"test\",\n",
        "    metric=\"f1\",\n",
        "    label_mapping=label2id,\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=10,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "Q4sBChKK6wnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uO_00j6hoA7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}